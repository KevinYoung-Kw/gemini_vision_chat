import os
import base64
from google.auth import default
import google.auth.transport.requests
import openai
import argparse
from pathlib import Path
from flask import Flask, request, jsonify, render_template_string

# è®¾ç½®è®¤è¯æ–‡ä»¶è·¯å¾„ï¼ˆç”¨æˆ·éœ€è¦å°†æ­¤æ›¿æ¢ä¸ºè‡ªå·±çš„æœåŠ¡è´¦å·å¯†é’¥æ–‡ä»¶ï¼‰
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "./ogcloud-458110-38b399810621.json"

# ä»ç¯å¢ƒå˜é‡ä¸­è·å–Google Cloudé¡¹ç›®IDï¼Œå¦‚æœæ²¡æœ‰è®¾ç½®åˆ™ä½¿ç”¨é»˜è®¤å€¼
GOOGLE_CLOUD_PROJECT_ID = os.environ.get("GOOGLE_CLOUD_PROJECT_ID", "ogcloud-458110")
# ä»ç¯å¢ƒå˜é‡ä¸­è·å–Google CloudåŒºåŸŸï¼Œå¦‚æœæ²¡æœ‰è®¾ç½®åˆ™ä½¿ç”¨é»˜è®¤å€¼
GOOGLE_CLOUD_LOCATION = os.environ.get("GOOGLE_CLOUD_LOCATION", "us-central1")

# HTMLæ¨¡æ¿ï¼Œç”¨äºåˆ›å»ºç®€å•çš„Webç•Œé¢
HTML_TEMPLATE = """
<!DOCTYPE html>
<html>
<head>
    <title>Gemini 2.5 æœ‰ç‚¹ç‰›é€¼çš„ æ¥ OpenAI-like æ¥å£</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }
        .container {
            display: flex;
            flex-direction: column;
            gap: 20px;
        }
        .input-section {
            display: flex;
            flex-direction: column;
            gap: 10px;
        }
        textarea {
            height: 100px;
            width: 100%;
            padding: 10px;
        }
        .file-upload {
            margin-top: 10px;
        }
        button {
            padding: 10px 15px;
            background-color: #4285f4;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            margin-top: 10px;
        }
        .response {
            margin-top: 20px;
            white-space: pre-wrap;
            background-color: #f9f9f9;
            padding: 15px;
            border-radius: 5px;
            border: 1px solid #ddd;
        }
        .stream {
            height: 300px;
            overflow-y: auto;
        }
        .footer {
            margin-top: 30px;
            text-align: center;
            font-size: 14px;
        }
        .footer a {
            color: #4285f4;
            text-decoration: none;
        }
    </style>
</head>
<body>
    <h1>Gemini 2.5 å¤šæ¨¡æ€æ¼”ç¤º</h1>
    <div class="container">
        <div class="input-section">
            <h2>è¾“å…¥æ–‡æœ¬</h2>
            <textarea id="prompt" placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."></textarea>
            
            <div class="file-upload">
                <h2>ä¸Šä¼ å›¾ç‰‡</h2>
                <input type="file" id="image-upload" accept="image/*">
                <div id="image-preview" style="margin-top: 10px;"></div>
            </div>
            
            <button id="submit-btn">æäº¤</button>
        </div>
        
        <div class="response">
            <h2>å“åº”</h2>
            <div id="response-content" class="stream"></div>
        </div>
    </div>

    <div class="footer">
        <a href="/test-api" target="_blank">æµ‹è¯•APIè¿æ¥</a>
    </div>

    <script>
        const imageUpload = document.getElementById('image-upload');
        const imagePreview = document.getElementById('image-preview');
        const promptTextarea = document.getElementById('prompt');
        const submitBtn = document.getElementById('submit-btn');
        const responseContent = document.getElementById('response-content');
        
        let base64Image = null;
        
        // å¤„ç†å›¾ç‰‡ä¸Šä¼ å¹¶æ˜¾ç¤ºé¢„è§ˆ
        imageUpload.addEventListener('change', function(e) {
            const file = e.target.files[0];
            if (!file) return;
            
            const reader = new FileReader();
            reader.onload = function(e) {
                const img = document.createElement('img');
                img.src = e.target.result;
                img.style.maxWidth = '300px';
                img.style.maxHeight = '300px';
                imagePreview.innerHTML = '';
                imagePreview.appendChild(img);
                
                // å­˜å‚¨base64ç¼–ç çš„å›¾åƒï¼ˆå»æ‰å¼€å¤´çš„data:image/jpeg;base64,ï¼‰
                base64Image = e.target.result.split(',')[1];
            };
            reader.readAsDataURL(file);
        });
        
        // æäº¤è¯·æ±‚
        submitBtn.addEventListener('click', async function() {
            const prompt = promptTextarea.value.trim();
            if (!prompt && !base64Image) {
                alert('è¯·è¾“å…¥æ–‡æœ¬æˆ–ä¸Šä¼ å›¾ç‰‡');
                return;
            }
            
            responseContent.textContent = 'æ­£åœ¨å¤„ç†...';
            submitBtn.disabled = true;
            
            try {
                // åˆ›å»ºè¯·æ±‚æ•°æ®
                const messages = [{
                    role: 'user',
                    content: []
                }];
                
                // æ·»åŠ æ–‡æœ¬éƒ¨åˆ†
                if (prompt) {
                    messages[0].content.push({
                        type: 'text',
                        text: prompt
                    });
                }
                
                // æ·»åŠ å›¾åƒéƒ¨åˆ†
                if (base64Image) {
                    messages[0].content.push({
                        type: 'image_url',
                        image_url: {
                            url: `data:image/jpeg;base64,${base64Image}`
                        }
                    });
                }
                
                // å‘é€è¯·æ±‚
                const response = await fetch('/generate', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({ messages: messages }),
                });
                
                if (response.status !== 200) {
                    // å°è¯•è§£æé”™è¯¯æ¶ˆæ¯
                    const errorData = await response.json();
                    throw new Error(`æœåŠ¡å™¨é”™è¯¯ (${response.status}): ${errorData.error || 'æœªçŸ¥é”™è¯¯'}`);
                }
                
                // å¤„ç†æµå¼å“åº”
                responseContent.textContent = '';
                const reader = response.body.getReader();
                const decoder = new TextDecoder();
                
                while (true) {
                    const { done, value } = await reader.read();
                    if (done) break;
                    
                    const text = decoder.decode(value);
                    responseContent.textContent += text;
                    responseContent.scrollTop = responseContent.scrollHeight;
                }
            } catch (error) {
                responseContent.textContent = `é”™è¯¯: ${error.message}`;
                console.error(error);
            } finally {
                submitBtn.disabled = false;
            }
        });
    </script>
</body>
</html>
"""

app = Flask(__name__)

def get_gemini_client(use_proxy=False, proxy_url=None):
    if use_proxy:
        # ä½¿ç”¨geminiapiä»£ç†
        if not proxy_url:
            raise ValueError("ä½¿ç”¨ä»£ç†æ¨¡å¼éœ€è¦æä¾›proxy_urlå‚æ•°")
            
        # è®¾ç½®OpenAIå®¢æˆ·ç«¯ä½¿ç”¨ä»£ç†URL
        client = openai.OpenAI(
            base_url=f"{proxy_url}/v1",
            api_key=os.environ.get("GEMINI_API_KEY", "YOUR_GEMINI_API_KEY")  # ä»ç¯å¢ƒå˜é‡è·å–æˆ–ä½¿ç”¨é»˜è®¤å€¼
        )
        
        # ä½¿ç”¨OpenAIå…¼å®¹çš„chat.completionsæ¥å£ï¼ˆé€šè¿‡ä»£ç†åˆ°Geminiï¼‰
        model_name = "google/gemini-2.5-pro-preview-05-06"  # geminiapié»˜è®¤ä¼šå°†æ­¤è½¬æ¢ä¸ºæ­£ç¡®çš„Geminiæ¨¡å‹
        print("\n==============================================================")
        print(f"ğŸ”„ ä½¿ç”¨ä»£ç†æ¨¡å¼è®¿é—®Gemini APIï¼š{proxy_url}")
        print(f"ğŸ¤– æ¨¡å‹ï¼š{model_name}")
        print("==============================================================\n")
    else:
        # ç›´æ¥ä½¿ç”¨Google Cloudçš„OpenAIå…¼å®¹ç«¯ç‚¹
        project_id = GOOGLE_CLOUD_PROJECT_ID
        location = GOOGLE_CLOUD_LOCATION
        
        # è·å–è®¿é—®ä»¤ç‰Œ
        credentials, _ = default(scopes=["https://www.googleapis.com/auth/cloud-platform"])
        credentials.refresh(google.auth.transport.requests.Request())
        
        # åˆ›å»ºOpenAIå®¢æˆ·ç«¯ï¼Œç¡®ä¿ä¼ é€’æ­£ç¡®çš„headers
        client = openai.OpenAI(
            base_url=f"https://{location}-aiplatform.googleapis.com/v1/projects/{project_id}/locations/{location}/endpoints/openapi",
            api_key=credentials.token,
            default_headers={"x-vertex-ai-endpoint": "true"}
        )
        
        # ä½¿ç”¨å®˜æ–¹æ¨èçš„modelåç§°æ ¼å¼ï¼Œç¡®ä¿ä½¿ç”¨æ”¯æŒè§†è§‰çš„å‹å·
        model_name = "google/gemini-2.5-pro-preview-05-06" # ä½¿ç”¨æ”¯æŒè§†è§‰çš„æ¨¡å‹
        print("\n==============================================================")
        print(f"â˜ï¸ ä½¿ç”¨Google Cloud Vertex AIè®¿é—®Gemini API")
        print(f"ğŸ”‘ é¡¹ç›®IDï¼š{project_id}ï¼ŒåŒºåŸŸï¼š{location}")
        print(f"ğŸ¤– æ¨¡å‹ï¼š{model_name}")
        print("==============================================================\n")
    
    return client, model_name

def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

@app.route('/')
def index():
    return render_template_string(HTML_TEMPLATE)

@app.route('/test-api')
def test_api():
    """æµ‹è¯•APIè¿æ¥å’Œè®¤è¯"""
    try:
        client, model_name = get_gemini_client()
        
        # ç®€å•æ–‡æœ¬è¯·æ±‚æµ‹è¯•
        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "user", "content": "Hello, are you working?"}],
            max_tokens=10,
            stream=False
        )
        
        return jsonify({
            "status": "success",
            "model": model_name,
            "response": response.choices[0].message.content
        })
    except Exception as e:
        import traceback
        return jsonify({
            "status": "error",
            "error": str(e),
            "traceback": traceback.format_exc()
        }), 500

@app.route('/generate', methods=['POST'])
def generate_response():
    try:
        data = request.json
        print(f"æ”¶åˆ°è¯·æ±‚æ•°æ®: {data}")
        
        # è·å–æŸ¥è¯¢å‚æ•°æ˜¯å¦ä½¿ç”¨ä»£ç†
        use_proxy = request.args.get('proxy', 'false').lower() == 'true'
        proxy_url = request.args.get('proxy_url', None)
        
        client, model_name = get_gemini_client(use_proxy=use_proxy, proxy_url=proxy_url)
        print(f"ä½¿ç”¨æ¨¡å‹: {model_name}")
        
        # æå–æ¶ˆæ¯å†…å®¹
        messages = data.get('messages', [])
        if not messages:
            return jsonify({"error": "è¯·æ±‚ä¸­ç¼ºå°‘messageså‚æ•°"}), 400
        
        print(f"è¯·æ±‚æ¶ˆæ¯ç»“æ„: {messages}")
        
        try:
            # æ£€æŸ¥æ¶ˆæ¯æ ¼å¼æ˜¯å¦æ­£ç¡®
            for message in messages:
                if 'role' not in message or 'content' not in message:
                    return jsonify({"error": "æ¶ˆæ¯æ ¼å¼é”™è¯¯ï¼Œéœ€è¦åŒ…å«roleå’Œcontentå­—æ®µ"}), 400
                
                # æ£€æŸ¥å¤šæ¨¡æ€æ ¼å¼æ˜¯å¦æ­£ç¡®
                if isinstance(message['content'], list):
                    for content_item in message['content']:
                        if 'type' not in content_item:
                            return jsonify({"error": "å¤šæ¨¡æ€å†…å®¹æ ¼å¼é”™è¯¯ï¼Œç¼ºå°‘typeå­—æ®µ"}), 400
            
            print("å¼€å§‹è°ƒç”¨API...")
            # æ ¹æ®OpenAIå…¼å®¹çš„å¤šæ¨¡æ€æ ¼å¼åˆ›å»ºè¯·æ±‚
            response = client.chat.completions.create(
                model=model_name,
                messages=messages,
                temperature=0.7,
                max_tokens=4096,
                stream=True
            )
            print("APIè°ƒç”¨æˆåŠŸï¼Œå¼€å§‹æµå¼è¾“å‡º...")
            
            # æµå¼è¾“å‡º
            def generate():
                try:
                    for chunk in response:
                        if hasattr(chunk.choices[0].delta, 'content') and chunk.choices[0].delta.content:
                            yield chunk.choices[0].delta.content
                except Exception as stream_error:
                    print(f"æµå¼è¾“å‡ºé”™è¯¯: {str(stream_error)}")
                    yield f"\né”™è¯¯: {str(stream_error)}"
            
            return app.response_class(generate(), mimetype='text/plain')
        
        except Exception as api_error:
            print(f"APIè°ƒç”¨é”™è¯¯: {type(api_error).__name__}: {str(api_error)}")
            return jsonify({"error": f"APIè°ƒç”¨é”™è¯¯: {str(api_error)}"}), 500
    
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        print(f"æœåŠ¡å™¨é”™è¯¯: {type(e).__name__}: {str(e)}")
        print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {error_details}")
        return jsonify({"error": f"æœåŠ¡å™¨é”™è¯¯: {str(e)}", "details": error_details}), 500

def main():
    parser = argparse.ArgumentParser(description='ä½¿ç”¨OpenAIå…¼å®¹æ ¼å¼çš„Gemini APIè¿›è¡Œå¤šæ¨¡æ€åˆ†æ')
    parser.add_argument('--proxy', action='store_true', help='ä½¿ç”¨geminiapiä»£ç†')
    parser.add_argument('--proxy-url', type=str, help='geminiapiä»£ç†çš„URLï¼Œä¾‹å¦‚ï¼šhttps://my-proxy.vercel.app')
    parser.add_argument('--image', type=str, help='è¦åˆ†æçš„å›¾ç‰‡è·¯å¾„')
    parser.add_argument('--prompt', type=str, default="æè¿°è¿™å¼ å›¾ç‰‡ä¸­çš„å†…å®¹", help='åˆ†æå›¾ç‰‡çš„æç¤º')
    parser.add_argument('--web', action='store_true', help='å¯åŠ¨Webç•Œé¢')
    parser.add_argument('--debug', action='store_true', help='å¯ç”¨è°ƒè¯•æ¨¡å¼')
    parser.add_argument('--show-path', action='store_true', help='æ˜¾ç¤ºAPIè°ƒç”¨è·¯å¾„ä¿¡æ¯å¹¶é€€å‡º')
    args = parser.parse_args()
    
    # å¦‚æœåªæƒ³æŸ¥çœ‹APIè·¯å¾„ä¿¡æ¯
    if args.show_path:
        client, model_name = get_gemini_client(use_proxy=args.proxy, proxy_url=args.proxy_url)
        print("APIè·¯å¾„æ£€æŸ¥å®Œæˆï¼Œç¨‹åºé€€å‡ºã€‚")
        return
        
    # è®¾ç½®æ˜¯å¦è°ƒè¯•æ¨¡å¼
    app.debug = args.debug
    
    if args.web:
        print("æ­£åœ¨å¯åŠ¨Webç•Œé¢ï¼Œè¯·è®¿é—® http://127.0.0.1:5000")
        if args.debug:
            print("è°ƒè¯•æ¨¡å¼å·²å¯ç”¨ï¼Œå°†æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—")
        
        # åœ¨å¯åŠ¨å‰æ˜¾ç¤ºAPIè·¯å¾„
        get_gemini_client(use_proxy=args.proxy, proxy_url=args.proxy_url)
        
        app.run(debug=args.debug)
        return
    
    if args.image:
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        image_path = Path(args.image)
        if not image_path.exists():
            print(f"é”™è¯¯ï¼šå›¾ç‰‡æ–‡ä»¶ {args.image} ä¸å­˜åœ¨")
            return
        
        # è·å–å®¢æˆ·ç«¯å’Œæ¨¡å‹
        client, model_name = get_gemini_client(use_proxy=args.proxy, proxy_url=args.proxy_url)
        
        # ç¼–ç å›¾ç‰‡ä¸ºbase64
        base64_image = encode_image(args.image)
        
        # åˆ›å»ºç¬¦åˆOpenAIè§„èŒƒçš„æ¶ˆæ¯
        messages = [
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": args.prompt
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{base64_image}"
                        }
                    }
                ]
            }
        ]
        
        # è°ƒç”¨API
        response = client.chat.completions.create(
            model=model_name,
            messages=messages,
            temperature=0.7,
            max_tokens=4096,
            stream=True
        )
        
        # æµå¼è¾“å‡ºå“åº”
        print("\n=== Gemini å¤šæ¨¡æ€åˆ†æ ===\n")
        try:
            for chunk in response:
                if hasattr(chunk.choices[0].delta, 'content') and chunk.choices[0].delta.content:
                    print(chunk.choices[0].delta.content, end="")
        except Exception as e:
            print(f"\né”™è¯¯: {str(e)}")
        print("\n")
    else:
        print("é”™è¯¯ï¼šè¯·æä¾›ä¸€ä¸ªå›¾ç‰‡æ–‡ä»¶è·¯å¾„æˆ–ä½¿ç”¨--webå‚æ•°å¯åŠ¨Webç•Œé¢")

if __name__ == "__main__":
    main()